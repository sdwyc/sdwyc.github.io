<!doctype html> <html lang="en"> <head> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Publication | Yinchuan Wang </title> <meta name="author" content="Yinchuan Wang"> <meta name="description" content="publications by categories in reversed chronological order. generated by jekyll-scholar."> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/cartoon_icon.png?7c1fbbf2e3403c73b6deee354fec38d1"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://sdwyc.github.io/publications/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Yinchuan</span> <span class="font-weight-bold">Wang</span> </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">Home </a> </li> <li class="nav-item active"> <a class="nav-link" href="/publications/">Publication <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">Blog </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Publication</h1> <p class="post-description">publications by categories in reversed chronological order. generated by jekyll-scholar.</p> </header> <article> <div class="publications"> <h2 class="bibliography">2024</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">IEEE T-IV</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/2024TIV-480.webp 480w,/assets/img/publication_preview/2024TIV-800.webp 800w,/assets/img/publication_preview/2024TIV-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/2024TIV.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="2024TIV.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="xu2024transformer" class="col-sm-8"> <div class="title">Transformer-based Traversability Analysis for Autonomous Navigation in Outdoor Environments with Water Hazard</div> <div class="author"> Mingrui Xu, <em>Yinchuan Wang</em>, Xiang Zhang, and <span class="more-authors" title="click to view 4 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '4 more authors' ? 'Donghui Mao, Chaoqun Wang, Rui Song, Yibin Li' : '4 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">4 more authors</span> </div> <div class="periodical"> <em>IEEE Transactions on Intelligent Vehicles</em>, Jun 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://ieeexplore.ieee.org/abstract/document/10574380" class="btn btn-sm z-depth-0" role="button">HTML</a> <a href="https://youtu.be/4B1XmBHgMXM?si=6-Ep6rfhPR_Ewawy" class="btn btn-sm z-depth-0" role="button">Video</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=Us-5jAQAAAAJ&amp;citation_for_view=Us-5jAQAAAAJ:Tyk-4Ss8FVUC" aria-label="Google Scholar link" role="button"> <img src="https://img.shields.io/badge/scholar-0-4285F4?logo=googlescholar&amp;labelColor=beige" alt="0 Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>Traversability analysis is of vital importance for autonomous vehicle navigation in outdoor environments. This paper focuses on the navigation algorithms in outdoor environments with water hazards, where the water areas can neither simply be neglected nor be deemed as non-traversable for safe and efficient navigation. To this end, we present a tightly-integrated navigation algorithms framework, which includes an environmental traversability analysis model and a control signal acquisition model. The traversability analysis model includes the SwinT-CGRU semantic segmentation model and the ConvCRFs water analysis model proposed in this paper. SwinT-CGRU can efficiently extract the feature from the input successive images, providing initial analysis of environmental traversability. To further analyze the water region, we employ a ConvCRFs, which determines the water traversability in an effective way. The results of the water traversability analysis are convincing for reliable vehicle navigation in outdoor scenarios. Based on the traversability analysis results, we propose a path planning approach by adapting the artificial potential field method to the image space. The control signal for steering and driving the vehicle can be acquired through an established mapping from the image space to the vehicle space. Experiments demonstrate that our segmentation model improves mIoU by 2.09-18.21% on the RELLIS-3D dataset. Furthermore, our navigation algorithm exhibits real-time performance and stability, ensuring the safety of vehicles in outdoor environments.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">xu2024transformer</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Transformer-based Traversability Analysis for Autonomous Navigation in Outdoor Environments with Water Hazard}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Xu, Mingrui and Wang, Yinchuan and Zhang, Xiang and Mao, Donghui and Wang, Chaoqun and Song, Rui and Li, Yibin}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{IEEE Transactions on Intelligent Vehicles}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jun</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/TIV.2024.3419846}</span><span class="p">,</span>
  <span class="na">dimensions</span> <span class="p">=</span> <span class="s">{false}</span><span class="p">,</span>
  <span class="na">google_scholar_id</span> <span class="p">=</span> <span class="s">{Tyk-4Ss8FVUC}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> <h2 class="bibliography">2023</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">CCC2023</abbr> </div> <div id="du2023comfortable" class="col-sm-8"> <div class="title">A Comfortable Interaction Strategy for the Visually Impaired Using Quadruped Guidance Robot</div> <div class="author"> Nianfei Du, <em>Yinchuan Wang</em>, Zhengguo Zhu, and <span class="more-authors" title="click to view 3 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '3 more authors' ? 'Yongsen Qin, Guoteng Zhang, Chaoqun Wang' : '3 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">3 more authors</span> </div> <div class="periodical"> <em>2023 42nd Chinese Control Conference (CCC)</em>, China Tianjin, Jul 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=Us-5jAQAAAAJ&amp;citation_for_view=Us-5jAQAAAAJ:d1gkVwhDpl0C" aria-label="Google Scholar link" role="button"> <img src="https://img.shields.io/badge/scholar-0-4285F4?logo=googlescholar&amp;labelColor=beige" alt="0 Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>A guidance robot that can guide its user to the destination smoothly and comfortably without rigorous training is expected to bring more convenience to the visually impaired. Although guidance robots have evolved considerably, little attention has been paid to the importance of human-robot interaction in the guidance process which will bring an unpleasant experience for the user when the amplitude of the interaction force increases. In this paper, we propose an interaction strategy for the visually impaired using quadruped guidance robot based on compliance control to make the user more comfortable to be guided. The user can track robot’s trajectory by perceiving the variation of traction force or manipulate the movement of the robot by applying force to the robot using proposed strategy. We also build a quadruped guidance robot system with an autonomous navigation algorithm. The robot can plan a safe path that ensures the user does not collide with obstacles when following the robot. Then the robot continuously interacts with its user while following the planned path to the goal to provide a comfortable experience. Experiments show that the interaction strategy we deployed in our quadruped guidance robot reduces traction force during guidance and improves the user experience.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">BIROB</abbr> </div> <div id="chen2023autonomous" class="col-sm-8"> <div class="title">Autonomous battery-changing system for UAV’s lifelong flight</div> <div class="author"> Jiyang Chen, Wenxi Li, Yingting Sha, and <span class="more-authors" title="click to view 5 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '5 more authors' ? 'Yinchuan Wang, Zhenqiang Zhang, Shikuan Li, Chaoqun Wang, Sile Ma' : '5 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">5 more authors</span> </div> <div class="periodical"> <em>Biomimetic Intelligence and Robotics</em>, Jun 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=Us-5jAQAAAAJ&amp;citation_for_view=Us-5jAQAAAAJ:9yKSN-GCB0IC" aria-label="Google Scholar link" role="button"> <img src="https://img.shields.io/badge/scholar-1-4285F4?logo=googlescholar&amp;labelColor=beige" alt="1 Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>Unmanned aerial vehicles (UAVs) lifelong flight is essential to accomplish various tasks, e.g., aerial patrol, aerial rescue, etc. However, traditional UAVs have limited power to sustain their flight and need skilled operators manually control their charging process. Manufacturers and users are eagerly seeking a reliable autonomous battery-changing solution. To address this need, we propose and design an autonomous battery-changing system for UAVs using the theory of inventive problem solving (TRIZ) and user-centered design (UCD) methods. For practical application, we employ UCD to thoroughly analyze user requirements, identify multiple pairs of technical contradictions, and solve these inconsistencies using TRIZ theory. Furthermore, we design an autonomous battery-changing hardware system that meets user requirements and realizes the battery change process after the automatic landing of UAVs. Finally, we conduct experiments to validate our system’s effectiveness. The experimental results show that our battery-changing system can implement the autonomous battery-changing task, and our system has high efficiency and robustness in the real environment.</p> </div> </div> </div> </li> </ol> <h2 class="bibliography">2022</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">2022IROS</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/2022IROS-480.webp 480w,/assets/img/publication_preview/2022IROS-800.webp 800w,/assets/img/publication_preview/2022IROS-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/2022IROS.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="2022IROS.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="chen2022low" class="col-sm-8"> <div class="title">Low-drift LiDAR-only Odometry and Mapping for UGVs in Environments with Non-level Roads</div> <div class="author"> Xiangyu Chen, <em>Yinchuan Wang</em>, Chaoqun Wang, and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'Rui Song, Yibin Li' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">2 more authors</span> </div> <div class="periodical"> <em>2022 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</em>, Japan Kyoto, Oct 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://ieeexplore.ieee.org/abstract/document/9982264" class="btn btn-sm z-depth-0" role="button">HTML</a> <a href="https://youtu.be/VWPcX7ydmU4?si=FGVex8ubNB4NphAn" class="btn btn-sm z-depth-0" role="button">Video</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=Us-5jAQAAAAJ&amp;citation_for_view=Us-5jAQAAAAJ:u5HHmVD_uO8C" aria-label="Google Scholar link" role="button"> <img src="https://img.shields.io/badge/scholar-1-4285F4?logo=googlescholar&amp;labelColor=beige" alt="1 Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>This study focuses on localization and mapping for UGVs when they are deployed in environments with non-level roads. In these scenarios, the vehicles need to travel through flat but not necessarily level grounds, i.e., ascent or descent, which may cause drifts of the robot pose and distortion of the map. We develop a low-drift LiDAR odometry and mapping approach for the UGV with LiDAR as the only exteroceptive sensor. A factor-graph based pose optimization method is developed with a specifically designed factor named slope factor. This factor includes the slope information that is estimated from a real-time LiDAR data stream. The slope information is also used to enhance the loop-closure detection procedure. Moreover, an incremental pitch estimation mechanism is designed to achieve further pose estimation refinement. We demonstrate the effectiveness of the developed framework in real-world environments. The odometry drift is lower and the map is more precise than experiments with the state-of-the-arts. Notably, on the Kitti dataset, our method also exhibits convincing performance, demonstrating its strength in more general application scenarios.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">chen2022low</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Low-drift LiDAR-only Odometry and Mapping for UGVs in Environments with Non-level Roads}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Chen, Xiangyu and Wang, Yinchuan and Wang, Chaoqun and Song, Rui and Li, Yibin}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{2022 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)}</span><span class="p">,</span>
  <span class="na">location</span> <span class="p">=</span> <span class="s">{Japan Kyoto}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{13174--13180}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">organization</span> <span class="p">=</span> <span class="s">{IEEE}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">oct</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/IROS47612.2022.9982264}</span><span class="p">,</span>
  <span class="na">dimensions</span> <span class="p">=</span> <span class="s">{false}</span><span class="p">,</span>
  <span class="na">google_scholar_id</span> <span class="p">=</span> <span class="s">{u5HHmVD_uO8C}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">ROBIO2022</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/2022ROBIO-480.webp 480w,/assets/img/publication_preview/2022ROBIO-800.webp 800w,/assets/img/publication_preview/2022ROBIO-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/2022ROBIO.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="2022ROBIO.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="wang2022information" class="col-sm-8"> <div class="title">Information Map Prediction based on Learning Network for Reinforced Autonomous Exploration</div> <div class="author"> <em>Yinchuan Wang</em>, Mingrui Xu, Xiangyu Chen, and <span class="more-authors" title="click to view 3 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '3 more authors' ? 'Xiang Zhang, Chaoqun Wang, Rui Song' : '3 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">3 more authors</span> </div> <div class="periodical"> <em>2022 IEEE International Conference on Robotics and Biomimetics (ROBIO)</em>, China Xishuangbanna, Dec 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://ieeexplore.ieee.org/abstract/document/10574380" class="btn btn-sm z-depth-0" role="button">HTML</a> <a href="https://youtu.be/AcaPfC4WGOs?si=gyKzjOvIhWOF8G8K" class="btn btn-sm z-depth-0" role="button">Video</a> <a href="https://github.com/sdwyc/informationMap.git" class="btn btn-sm z-depth-0" role="button">Code</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=Us-5jAQAAAAJ&amp;citation_for_view=Us-5jAQAAAAJ:u-x6o8ySG0sC" aria-label="Google Scholar link" role="button"> <img src="https://img.shields.io/badge/scholar-0-4285F4?logo=googlescholar&amp;labelColor=beige" alt="0 Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>Autonomous exploration is the prerequisite for reliable robot navigation in unknown environments via providing the necessary information. The goal is to build a precise environment map while at the same time locating the robot robustly. To achieve this goal, this paper develops an information map that jointly provides the information of mapping and localization uncertainty. It consists of a localization uncertainty map and a model uncertainty map. The former evaluates the landmarks around the robot and the latter indicates the map completeness based on information theory. The information map serves as the input for making better decisions of where-to-go to achieve higher localization and mapping performance. To improve the efficiency of information map prediction, we develop a learning-based map prediction framework, where a dataset is established autonomously. The effectiveness and efficiency of the developed framework are verified through experiments in simulation environments.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">wang2022information</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Information Map Prediction based on Learning Network for Reinforced Autonomous Exploration}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Wang, Yinchuan and Xu, Mingrui and Chen, Xiangyu and Zhang, Xiang and Wang, Chaoqun and Song, Rui}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{2022 IEEE International Conference on Robotics and Biomimetics (ROBIO)}</span><span class="p">,</span>
  <span class="na">location</span> <span class="p">=</span> <span class="s">{China Xishuangbanna}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1982--1988}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">organization</span> <span class="p">=</span> <span class="s">{IEEE}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">dec</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/ROBIO55434.2022.10011800}</span><span class="p">,</span>
  <span class="na">dimensions</span> <span class="p">=</span> <span class="s">{false}</span><span class="p">,</span>
  <span class="na">google_scholar_id</span> <span class="p">=</span> <span class="s">{u-x6o8ySG0sC}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> </div> </article> </div> </div> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?b7816bd189846d29eded8745f9c4cf77"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.min.js" integrity="sha256-rjmgmaB99riUNcdlrDtcAiwtLIojSxNyUFdl+Qh+rB4=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?601a2d3465e2a52bec38b600518d5f70"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let theme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===theme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-home",title:"Home",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-publication",title:"Publication",description:"publications by categories in reversed chronological order. generated by jekyll-scholar.",section:"Navigation",handler:()=>{window.location.href="/publications/"}},{id:"nav-blog",title:"Blog",description:"",section:"Navigation",handler:()=>{window.location.href="/blog/"}},{id:"post-\u6df7\u5408\u6574\u6570\u89c4\u5212\u4e0e\u6df7\u5408\u6574\u6570\u4e8c\u6b21\u89c4\u5212",title:"\u6df7\u5408\u6574\u6570\u89c4\u5212\u4e0e\u6df7\u5408\u6574\u6570\u4e8c\u6b21\u89c4\u5212",description:"MIP, MIQP\u4ecb\u7ecd\u548c\u5b9e\u4f8b\u5e94\u7528",section:"Posts",handler:()=>{window.location.href="/blog/2024/%E6%B7%B7%E5%90%88%E6%95%B4%E6%95%B0%E8%A7%84%E5%88%92%E4%B8%8E%E6%B7%B7%E5%90%88%E6%95%B4%E6%95%B0%E4%BA%8C%E6%AC%A1%E8%A7%84%E5%88%92/"}},{id:"post-\u4ee5slamer\u89d2\u5ea6\u770b\u5f85gn\u548clm\u7b97\u6cd5",title:"\u4ee5SLAMer\u89d2\u5ea6\u770b\u5f85GN\u548cLM\u7b97\u6cd5",description:"\u7528\u767d\u8bdd\u4ecb\u7ecdGN\u548cLM\u7b97\u6cd5",section:"Posts",handler:()=>{window.location.href="/blog/2024/%E4%BB%A5SLAMer%E8%A7%92%E5%BA%A6%E7%9C%8B%E5%BE%85GN%E5%92%8CLM%E7%AE%97%E6%B3%95/"}},{id:"news-mip-amp-amp-miqp-blog-released",title:"\ud83d\udcdc\ud83d\udcdc MIP &amp; MIQP Blog Released!",description:"",section:"News"},{id:"news-one-cooperated-paper-is-accepted-by-ieee-t-iv",title:"\ud83c\udf89\ud83c\udf89 One cooperated paper is accepted by IEEE T-IV!",description:"",section:"News"},{id:"news-busts-in-silhouette-busts-in-silhouette-attending-icra-2024-attendance-in-japan-yokohama",title:'<img class="emoji" title=":busts_in_silhouette:" alt=":busts_in_silhouette:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f465.png" height="20" width="20"><img class="emoji" title=":busts_in_silhouette:" alt=":busts_in_silhouette:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f465.png" height="20" width="20"> Attending ICRA 2024 attendance in Japan Yokohama.',description:"",section:"News"},{id:"news-hap-paper-is-accepted-by-icra-2024",title:"\ud83c\udf89\ud83c\udf89 HAP paper is accepted by ICRA 2024!",description:"",section:"News"},{id:"news-the-first-time-to-establish-this-page",title:"\ud83c\udf89\ud83c\udf89 The first time to establish this page.",description:"",section:"News"},{id:"projects-project-1",title:"project 1",description:"with background image",section:"Projects",handler:()=>{window.location.href="/projects/1_project/"}},{id:"projects-project-2",title:"project 2",description:"a project with a background image and giscus comments",section:"Projects",handler:()=>{window.location.href="/projects/2_project/"}},{id:"projects-project-3-with-very-long-name",title:"project 3 with very long name",description:"a project that redirects to another website",section:"Projects",handler:()=>{window.location.href="/projects/3_project/"}},{id:"projects-project-4",title:"project 4",description:"another without an image",section:"Projects",handler:()=>{window.location.href="/projects/4_project/"}},{id:"projects-project-5",title:"project 5",description:"a project with a background image",section:"Projects",handler:()=>{window.location.href="/projects/5_project/"}},{id:"projects-project-6",title:"project 6",description:"a project with no image",section:"Projects",handler:()=>{window.location.href="/projects/6_project/"}},{id:"projects-project-7",title:"project 7",description:"with background image",section:"Projects",handler:()=>{window.location.href="/projects/7_project/"}},{id:"projects-project-8",title:"project 8",description:"an other project with a background image and giscus comments",section:"Projects",handler:()=>{window.location.href="/projects/8_project/"}},{id:"projects-project-9",title:"project 9",description:"another project with an image \ud83c\udf89",section:"Projects",handler:()=>{window.location.href="/projects/9_project/"}},{id:"socials-email",title:"Send email",section:"Socials",handler:()=>{window.open("mailto:%73%64%77%79%63@%6D%61%69%6C.%73%64%75.%65%64%75.%63%6E","_blank")}},{id:"socials-google-scholar",title:"Google Scholar",section:"Socials",handler:()=>{window.open("https://scholar.google.com/citations?user=Us-5jAQAAAAJ","_blank")}},{id:"socials-github",title:"GitHub",section:"Socials",handler:()=>{window.open("https://github.com/sdwyc","_blank")}},{id:"socials-youtube",title:"YouTube",section:"Socials",handler:()=>{window.open("https://youtube.com/@yinchuanwang3591","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> <script src="/assets/js/shortcut-key.js"></script> </body> </html>